% !TEX root = ../thesis.tex
%
\chapter{A Large Real Noisy Image Dataset, with A Comprehensive Evaluation of State-of-the-arts}
\label{sec:dataset}

\section{Introduction}

The statistical peorperties of realistic noise has been thoroughly studied for CCD and CMOS image sensors. The realistic noise related to the CCD or CMOS sensors could be divided into five major sources, including photon shot noise, fixed pattern noise, dark current, readout noise, and quantization noise, etc.

The shot noise is one inevitable source of noise and induced by the stochastic arrival process of photons to the sensor. This can be modeled by Possion distribution. This type of noise is proportional to the mean intensity of the specific pixel and is not stationary across the whole image. The fixed pattern noise include pixel response non-uniformity (PRNU) noise and dark current non-uniformity (DCNU) noise. PRNU means for a fixed light level, each pixel will have a slightly different output levels or responses. The major reason for the PRNU noise is the loss of light and color mixture in the neighboring pixels.

The dark current and fixed pattern noise are from the electronics within the sensor chip, while the readout noise and quantization noise are from discretization. The dark current is generated mainly  due to thermal agitation, even thouth there is no light reaching the camera sensor. The readout noise is mainly generated during the process of Charge to voltage conversion. The readout is inheretantly not accurate. This is also the reason for quantization noise, in which the readout value is quantizated to be an integer. The final pixel values are only discretization of the original raw pixel values. Other types of noise include CCD specific sources such as transfer efficiency and CMOS specific sources such as column noise.

As we have presented in the previous chapters, the image denoising task is very differetn when dealing with real noisy images when compared to the synthetic additive white Gaussian noise (AWGN). This is due to that the realistic noise is signal dependent while the AWGN noise is independent of the signals. Another key reason is that in-camera imaging pipeline will make the noise much more complex when compared with that in the raw image data.

Another issue about the real noisy image denoising is that the images with realistic noise has no ideal ground truth, i.e., the noise-free image. Hence, the objective evaluation about the image quality on the images denoised by existing methods should be nearly impossible. However, the image quality assessment by subjectiva evaluation would be very biased due to the limited number of subjectives in the evaluation experiments and the control of the experimental process. The missing of ground truth will be very problematic we have no objective measurements to evaluate the image quality of the images denoised by different methods. 

In order to address the challenge of missing ground truth of the realistic noisy images, we propose to construct a dataset for realistic photographs with reasonble noise-free ground truth images. Our basic idea is inspired by the paper of \cite{crosschannel}, in which a small dataset is set up for analysising the properties of realistic noise, but the post-processing is less refined. Image pairs appear to exhibit spatial misalignment, the intensity transform does not model heteroscedastic noise, and low-frequency bias is not removed. Our experiments
indicate that ignoring these sources of error significantly affects the realism of the dataset. Moreover, \cite{} is based on $8$-bit demosaiced images while we work with untainted linear raw intensities.

It is often useful to measure the noise characteristics of a sensor at a certain ISO level. \cite{} proposes to illuminate the sensor with approximately constant irradiation and subsequently aggregates intensity measurements spatially. This is repeated for different irradiation levels to capture the intensity dependence of the noise. \cite{} propose a less tedious capture protocol similar to ours, where multiple exposures of a static scene are used to aggregate the measurements at every pixel site temporally. In contrast, our Tobit regression allows to estimate the parameters of the noise process by having access to just two images.


\section{Related Work}

There are only a few work focus on benchmarking the denoising methods on realistic noisy images. The first effort on constructing a dataset on real noisy images is the RENOIR dataset \cite{}. It relies on taking sets of images of a static scene with different ISO values. However, the post-processing is less refined. Image pairs appear to exhibit spatial misalignment, the intensity transform does not model heteroscedastic noise, and low-frequency bias is not removed. In \cite{}, experiments have been evaluated to validate that ignoring these sources of error significantly
affects the realism of the dataset. It is often useful to measure the noise characteristics of a sensor at a certain ISO level. \cite{} proposes to illuminate the sensor with approximately constant irradiation and subsequently aggregates intensity measurements spatially. This is repeated for different irradiation levels to capture the intensity dependence of the noise. \cite{} propose a less tedious capture protocol similar to ours, where multiple exposures of a static scene are used to aggregate the measurements at every pixel site temporally. In contrast, our Tobit regression allows to estimate the parameters of the noise process by having access to just two images.

The second work in this direction is proposed in the \cite{crosschannel}, in which 11 static scenes are collected as a dataset including realistic noisy images. For each scene, 500 JPEG images are captured and the mean image of each scene is computed to generate the ground truth noise-free image. Using the mean of temporal images as noise-free image has also been employed in \cite{Liu2008,liupractical}. In this dataset, the images are with resolution $7630\times4912$ captured by Nikon D800 (ISO=1600, 3200, 6400), Nikon D600 (ISO=3200), and Canon 5D Mark III (ISO=3200). The major problems of this dataset is that the captured images are almost printed scenes, which share similar nosie statistical property. 

The third work in this direction is recently proposed in the \cite{dndnoise}. The proposed DND benchmark for denoising algorithms consists of 50 scenes selected from their captured images. In order to obviate the unrealistic setting by developing a methodology for benchmarking denoising techniques on real photographs. The authors in \cite{dndnoise} capture pairs of images with different ISO values and appropriately adjusted exposure times, where the nearly noise-free low-ISO image serves as reference. To derive the ground truth, careful post-processing is needed. They correct spatial misalignment, cope with inaccuracies in the exposure parameters through a linear intensity transform based on a novel heteroscedastic Tobit regression model, and remove residual low-frequency bias that stems, e.g., from minor illumination changes. They then capture a novel benchmark dataset, the Darmstadt Noise Dataset (DND), with consumer cameras of differing sensor sizes. One interesting finding is that various recent techniques that perform well on synthetic noise are clearly outperformed by BM3D on photographs with real noise. This benchmark delineates realistic evaluation scenarios that deviate strongly from those commonly used in the scientific literature.


\section{Dataset Construction}

In order to construct a more suitable dataset for comparison on the existing denoising methods, we need a new dataset which can eliminate the problem mentioned above. The camera we use are the Canon 5D, Nikon D800, Olympus, and Sony A7II. The brands are more versatile than the above mentioned three datasets. In addition, we use the raw data of mobile phone. 

There are several problems hindering us from touching the raw data of mobile phone. The first one is that most mobile phones do not support the raw data output. Even the raw data of  iPhone is processed before being output, not the original one. Here, we use the raw data of the iPhone and process it for the final RGB images. The second problem is that it is hard to capture the static image with hundreds of repetition with mobile phone. The solution is that we can use apple watch to remote control the iPhone for image capturing. 

The format of our captured images are raw data and JPEG images with uncompressed process. For each scene, we capture it for 500 times, just as \cite{crosschannel} did. The focus is set by firstly automatic and then mannually when capturing the images. We capture the images indoor with normal lighting condition, dark lighting condition, and the outdoor normal lighting condition.


\section{Analysis and Discussion}


\section{Experiments}










\section{Conclusion}