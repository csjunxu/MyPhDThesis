% !TEX TS-program = pdflatex
% !TEX root = ../thesis.tex
%

\chapter{Introduction}
\label{sec:intro}

Nowadays, CCD or CMOS cameras are becoming more and more important in many aspects of human life such as photography, security system, and robots, etc. For each camera product, the camera imaging pipeline in the camera is of particular importance since it is the core part to transform the photons reflected by the real scene being captured in the camera sensor into the pixel values of an image, which can be displayed on a screen. During the camera imaging process, the noise is unavoidablely generated due to many reasons. Two major reasons of noise generation are the discrete nature of light and the thermal agitation, which can cause the photon shot noise and the dark-current noise, respectively. Image denoising is the problem of recovering the laten clean image from the captured noise version. 

\textbf{Chapter abstract} This chapter will introduce the image noise and its acquirezation equation, the image denoising problem, the objective measures to evaluate the image denoising performance, the proposed denoising methods. Finally, I will summarize the structural of this thesis, and the contribution I made in this thesis.

%\section{The Camera Imaging Pipeline}
%\label{sec:intro:general}

%The cameras capture the images and store as raw image formats. During the camera imaging pipeline, the photons are transformed into electronics by the photodiode in the camera sensor. The original sensor arrat (also called color filter array, or CFA) contains red, green, and blue channels, and these incomplete channels are transformed into the final RGB files via the raw converter. The camera imaging pipeline includes multiple stages such as reading raw image, black light subtraction, lens correction, demosaicing, noise reduction, white balancing, gamma curve, final color space conversion, etc \cite{browneccv2016}. Basically, a camera imaging pipeline includes demosaicing, white balancing and color space transform, gamut mapping, tone mapping, and JPEG compression \cite{crosschannel2016}. However, different cameras have varying structures and camera parameters, and hence resulting different imaging effects. Recently, there also exists learning based imaging pipelines which directly learn the  natural image priors from the RGB and raw images pairs.


\section{The Image Noise Formulation}
\label{sec:intro:current}

Due to the discrete nature of light and the thermal agitation, the camera sensors will cause inaccurate measurement in camera sensors. The inaccurate measurement is also called image noise. The types of image noise generated during the imaging pipeline are mainly the random noise, the spatial non-uniformity noise, and quantization noise. The random noise includes photon shot noise, dark current, and readout noise. The spatial non-uniformity noise includes the fixed pattern noise (PRNU, DCNU), CCD/CMOS specific noise. During the camera imaging pipeline, the noise will be furtherly made complex than those in the raw images.

To better analysis the property of the realistic noise quantitatively, we provide a simplified signal acquisition model \cite{Foipractical} including various noise sources (for each pixel) as follows:
\begin{equation}
\label{e11}
\bm{P} = f((g_{cv}(\bm{C}+\bm{D})+\bm{N}_{reset})g_{out}+\bm{N}_{out})+\bm{Q}.
\end{equation}
The above equation is explained in details as follows: 
\begin{itemize}
\item $\bm{P}$ is the raw pixel value;
\item $f$ is the camera response function, usually a linear function before attaining a saturation threshold;
\item $\bm{C}$ is the number of absorbed electrons (charges) transformed from the photons via the photon-diodes in the camera sensor, which can be modeled by a Poisson distribution;
\item $\bm{D}$ is the number of absorbed electrons generated by dark current by thermal generation, which is often modeled by a Poisson distribution;
\item $\bm{N}_{reset}$ is the thermal noise generated by the readout circuitry (or reset noise related to reset voltage), which can be well modeled by a Gaussian disribution;
\item $\bm{N}_{out}$ is the readout noise, which is also modeled by a Gaussian distribution;
\item $\bm{Q}$ is the quantization error happened during rounding to interger values, usually uniformly distributed and normally negligible compared to the readout noise;
\item $g_{cv}$ is the equivalent capacitance (EC) of the photo-diode and the gain factor during charge to voltage conversion;
\item $g_{out}$ is the gain factor during voltage to pixel value conversion (readout).
\end{itemize}
After some merging and simplifying, the signal acquisition model \ref{e11} can be formulated as follows:
\begin{equation}
\label{e12}
\begin{split}
\textbf{P} 
&=f((g_{cv}(\textbf{C}+\textbf{D})+\textbf{N}_{reset})g_{out}+\textbf{N}_{out})+\textbf{Q},
\\
&=f(g_{cv}g_{out}(\textbf{C}+\textbf{D})+g_{out}\textbf{N}_{reset}+\textbf{N}_{out})+\textbf{Q},
\\
&=f(g\lambda+N_{R})+\textbf{Q},
\end{split}
\end{equation}
where $g = g_{cv}g_{out}$ is the overall camera gain factor, $\lambda=\textbf{C}+\textbf{D}$ is number of electrons in pixel capacitor, and $N_{R}=g_{out}\textbf{N}_{reset}+\textbf{N}_{out}$ is the overall readout noise. In summary, the overall noise before the camera imaging pipeline can be modeled by a mixed Poisson and Gaussian distribution \cite{Foipractical}. Unfortunately, the realistic noise will become much more complex after being processed in the camera imaging pipeline \cite{crosschannel2016}. This makes the image denoising an important and challenging task. 

To test the ability of denoising methods, in image denoising community, the most common testing noise is additive white Gaussian noise (AWGN) \cite{bm3d,ksvd}. The images with AWGN noise are corrupted by random values following Gaussian distribution with zero mean and a certain standard deviation (std). Note that for each pixel in AWGN noise degraded image, the std of the Gaussian distributed noise is the fixed, while for all the pixels, the values of the noise are sampled independently. 

\section{Image Denoising}

Based on the above analysis, image denoising is an essential step for recovering better image quality. In most literature, the AWGN noise is described as a Gaussian distribution $\mathcal{N}(0,\sigma^{2})$, where $0$ is the mean of the Gaussian distribution and $\sigma$ is the standard deviation (std). Most of existing denoising methods focus on dealing with AWGN noise since it is a perfect testing bed for evaluating the proposed methods as well as other image restoration problems such as image super-resolution, deblurring, inpainting, etc.

In general, image denoising aims to recover the latent clean image $\bm{x}$ from the observed noisy image $\bm{y}=\bm{x}+\bm{n}$, where $\bm{n}$ is assumed to be the additive noise. $\bm{n}$ is often assumed to be synthetic additive white Gaussian noise, or the realistic noise in real-world images. Image denoising can be viewed as a regression problem, in which a \textsl{plausible} clean image can be obtained from the infinite number of possible candidates. The word \textsl{plausible} means that the denoised image should look like the noisy image but without the noise component. 

Image denoising would be very hard if we do not employ any prior information on it. The reason is that we do not know what exactly the latent clean image is without the prior information of the clean image. Hence, it is meaningful to exploit the most \textsl{plausible} image under some prior information. The most commonly used prior information in image denoising community is the Bayesian rule, which is also known as maximum A-posterior (MAP) property. Under the MAP framework, the most \textsl{plausible} latent clean image is the one which has the maximum Bayesian probability given the given noisy version. The posteriro probability can be measured by some existing evaluation methods which I will introduce in the following sections. In fact, the probability or measurements can measure the closeness of the latent clean image to the given noisy image. The closeness is usually measured by the $\ell_{2}$ norm of the difference between the two images mentioned above. There are many latent clean images with the same $\ell_{2}$ norm distance with the given noisy image. But some images in the circle are more \textsl{plausible} than the others due to the aspects of less artifacts, better structural preservation, and less remaining noise, etc. 


\section{Evaluating Denoising Performance}

In order to achieve the maximum Bayesian probability, we need calculate the measurements of goodness for the denoised images. A natural problem is, how to measure the quality of the denoised image? It is very important to find better answer to this question. In fact, the research of image quality accessment is to find good algorithms to measure the quality of images under different situations and applications including image denoising. 

A initial understanding is that the answer to the above question is largely depends on the situations we face when we perform image denoising experiments. When we perform synthetic experiments on additive white Gaussian nosie (AWGN), we usually already have the original clean image, the noisy image is generated by adding synthetic AWGN noise to the clean image. Then we can directly measure the quality of the denoised image by some existing image quality assessment (IQA) metrics. When we do not have the clean image provided as ``ground truth'', a possible and final solution is to measure the image quality by relying on human subjective evaluation. The IQA metrics can be roughly divided into two major directions: 1) full reference IQA; and 2) no reference IQA. Full reference IQA metrics are based on the assumption that the true underlying image is available in order to compute a measure, while no reference IQA metrics perform quality assessments without the reference image since the true underlying image is not available. 

\textbf{RMSE and PSNR}: We mentioned previously that the it is corresponding to the $\ell_{2}$ norm or equally mean square error (MSE) which is used to measure the distance between the denoised image and the given noisy image. In fact, the MSE measure is closely related to the famous peak signal to noise ratio (PSNR) metric. PSNR is the most commonly used full reference IQA metric for many image restoration tasks including denoising. The definition of PSNR can be formulated as follows (for 8-bit image):
\begin{equation}
\text{PSNR}
=
20\text{log}_{10}
(\frac{2^{8}}{\text{RMSE}(\bm{x},\bm{y})}),
\end{equation}
where $\text{RMSE}(\bm{x},\bm{y})$ refers to the root mean square error defined as $\text{RMSE}=\sqrt{\frac{1}{MN}\sum_{i=1}^{M}\sum_{j=1}^{N}(\bm{x}_{ij}-\bm{y}_{ij})^{2}}$ for images $\bm{x},\bm{y}\in\mathcal{R}^{M\times N}$. As we can see, PSNR is closely related to the $\ell_{2}$ norm distance between two images. The unit of PSNR is decibel (dB) and higher dB value indicates better image quality and lower RMSE. Even thouth PSNR is very simple and intuitive, higher PSNR does not indicate higher visual structural similarity. Hence, many researchers still make effort to find alternative and better IQA metrics.

\textbf{SSIM} \cite{ssim}: Some researchers attempted to exploit the visual properties of the human visual system. One of the seminar work in this direction is the famous structural similarity index metric (SSIM), which is a full reference IQA metric. In SSIM, each image patch is separated into three different components indicating three core informative parts of the original patch. The three components are luminance (mean value of the pixels in the patch), contrast (the standard deviation of the patch), and structure (the mean subtracted patch). The major advantage of the SSIM is that it takes into account the fact that the human visual system is very sensitive tothe relative changes in luminance, rather than the absolute changes in luminance. The value range of the SSIM is between 0 and 1, where higher value indicate higher similarity (SSIM of 1 indicates that the two images are exactly the same). Note that it does not indicate that higher SSIM indicate better image quality, since the reference image is not the image of the best quality. 

\textbf{Other IQA Metrics}: Besides of the PSNR and SSIM, there are many other IQA metrics for full reference and no reference IQA. Some examples include the MS-SSIM \cite{msssim}, which is a multi-scale extension of the original SSIM. Some examples in no reference IQA include BLIINDS \cite{bliinds} and BIQI \cite{biqi}. These IQA metrics capture the deviations from the expected statistics of the natural images. For example, BLIINDS measures the deviations from the expected histogram of certain features in DCT domain, while BIQI measures deviations from the expected distribution of wavelet coefficients in a multi-scale decomposition.

I have to mention that no IQA metric is perfect or best for image denoising task, both in full reference and no reference cases. The de facto standard metrics in image restoration community are PSNR and SSIM. In order to avoid these two metrics generate bad results, it is essential to demonstrate the image quality in the thesis for human subjective evaluation.


\section{Literature Review}

In this chapter, I will review the methods related to denoising in literature during the past decades. These methods can be divided into three categories. Firstly, I will review the denoising methods designed for additive white Gaussian noise (AWGN) since AWGN is the mostly studied noise distribution inthe literature. Though these methods are proposed to deal with the AWGN noise, the idea can be applied to the other image denoising tasks such as real color image denoising. Secondly, I will review the existing methods proposed for processing real noisy images. Though the methods in this domain is not that versartile than those methods for the AWGN noise, the real noisy image denoising is the current mainstream for the image denoising community. Due to the noise is not known beforehand, noise estimation should be performed for the real noisy image denoising task. Finally, I will also review the image noise estimation methods in the literature.

However, noise in real images is more complex than simple Gaussian or mixed Gaussian and impulse distribution. Besides, noise is usually unknown for existing methods. This makes image denoising still a challenging problem.

\section{Synthetic Grayscale Image Denoising}
\label{sec:review:sys}

As a classical problem in low level vision, image denoising has been extensively studied in the past decades, yet it is still an active topic for the reason that it provides an ideal test bed for image modeling techniques. In general, image denoising aims to recover the clean image $\mathbf{x}$ from its noisy observation $\mathbf{y} = \mathbf{x} + \mathbf{n}$, where $\mathbf{n}$ is the additive noise which is often assumed to be additive white Gaussian noise (AWGN). Other types of noise, e.g., Poisson noise and salt-and-pepper noise, are also been studied in the literature. The Poisson noise can be transformed into the additive noise after some transformation. Besides, the salt-and-pepper noise is naturally additive noise and can be formulated into the model mentioned above.

A variety of image denoising methods have been developed in past decades, including diffusion based methods \cite{PeronaMalik1990}, total variation based methods \cite{rudin1992nonlinear,osher2005iterative}, filtering based methods \cite{Tomasi1998}, wavelet/curvelet based methods \cite{softthresholding,bayesshrink,curvelet}, nonlocal self-similarity based methods \cite{nlm,bm3d}, sparse representation based methods \cite{ksvd,lssc,ncsr}, and low rank based methods \cite{nnm,wnnm}, etc. Recently, some discriminative denoising methods have also been developed by learning discriminative priors from pairs of clean and noisy images \cite{mlp,csf,tnrd}.

Image modeling plays a central role in image denoising. By modeling the wavelet transform coefficients as Laplacian distributions, many wavelet shrinkage based denoising methods such as the classical soft-thresholding \cite{softthresholding} have been proposed.\ Chang et al. modeled the wavelet transform coefficients as generalized Gaussian distribution, and proposed the BayesShrink \cite{bayesshrink} algorithm.\ By considering the correlation of wavelet coefficients across scales, Portilla et al.  \cite{blsgsm} proposed to use Gaussian Scale Mixtures for image modeling and achieved promising denoising performance. It is widely accepted that natural image gradients exhibit heavy-tailed distributions \cite{weiss}, and the total variation (TV) based methods \cite{rudin1992nonlinear,osher2005iterative} actually assume Laplacian distributions of image gradients for denoising. The Fields of Experts (FoE) \cite{foe} proposed by Roth and Black models the filtering responses with Student's t-distribution to learn filters through Markov Random Field (MRF) \cite{Bishop}. Recently, Schmidt and Roth proposed the cascade of shrinkage fields (CSF) to perform denoising efficiently \cite{csf}.

Instead of modeling the image statistics in some transformed domain (e.g., gradient domain, wavelet domain or filtering response domain), another popular approach is to model the image priors on patches. One representative is the sparse representation based scheme which encodes an image patch as a linear combination of a few atoms selected from a dictionary \cite{olshausen1996emergence,olshausen1997sparse,ksvd}. The dictionary can be chosen from the off-the-shelf dictionaries (e.g., wavelets and curvelets), or it can be learned from natural image patches.\ The seminal work of K-SVD \cite{ksvdtsp,ksvd} has demonstrated promising denoising performance by dictionary learning, which has yet been extended and successfully used in various image processing and computer vision applications \cite{srcolor,srcvpr,lcksvd}. By viewing image patches as samples of a multivariate variable vector and considering that natural images are non-Gaussian, Zoran and Weiss \cite{epll,gmmnips} and Yu et al.  \cite{ple} used Gaussian Mixture Model (GMM) to model image patches, and achieved state-of-the-art denoising and image restoration results, respectively.

When the input is a noisy RGB color image, there are mainly three strategies for color image denoising. (1) The first strategy is to apply the grayscale image denoising algorithm to each channel. However, such a straightforward solution
will not exploit the spectral correlation among RGB channels, and the denoising performance may not be very satisfying. (2) The second strategy is to transform the RGB image into a less correlated color space, such as YCbCr, and perform denoising in each channel of the transformed space \cite{foe,cbm3d}. One representative work along this line is the CBM3D algorithm \cite{cbm3d}. However, the color transform will complicate the noise distribution, and the correlation among color channels is not fully exploited. (3) The third strategy is to perform joint denoising on the RGB channels simultaneously for better use of the spectral correlation. For example, the patches from RGB channels are concatenated as a long vector for processing \cite{mairal2008sparse,Zhu_2016_CVPR}.

Though joint denoising of RGB channels is a more promising way for color image denoising, it is not a trivial extension from single channel (grayscale image) to multiple channels (color image).\ The noise in standard RGB (sRGB) space can be approximately modeled as AWGN, but it has different variances for different channels \cite{Liu2008,Leungtip,crosschannel2016} due to the sensor characteristics and on-board processing steps in digital camera pipelines \cite{crosschannel2016,karaimer_brown_ECCV_2016}.\ This makes the real color image denoising problem much more complex.\ If the three channels are treated equally in the joint denoising process, false colors or artifacts can be generated \cite{mairal2008sparse}.\ How to account for the different noise characteristics in color channels, and how to effectively exploit the within and cross channel correlation are the key issues for designing a good color image denoising method.



\section{Realistic Color Image Denoising}
\label{sec:review:feature}

During the last decade, a few methods have been proposed for real color image denoising.\ To the best of our knowledge, the study of real color image denoising can be traced back to the BLS-GSM model \cite{blsgsm}. In \cite{blsgsm}, Portilla et al. proposed to use scale mixture of Gaussian in overcomplete oriented pyramids to estimate the latent clean images. In \cite{fullyblind}, Portilla proposed to use a correlated Gaussian model for noise estimation of each wavelet subband. Based on the robust statistics theory \cite{huber2011robust}, Rabie modeled the noisy pixels as outliers, which could be removed via Lorentzian robust estimator \cite{rabie2005robust}. The CBM3D method \cite{cbm3d} is a representative color image denoising method, which first transforms the RGB image into a luminance-chrominance space (e.g., YCbCr) and then applies the benchmark BM3D method \cite{bm3d} to each channel separately.\ The non-local similar patches are grouped by the luminance channel.\ In \cite{Liu2008}, Liu et al.\ proposed the ``Noise Level Function'' to estimate the noise for each channel in natural images, and then use Gaussian conditional random field to obtain the latent clean image \cite{Liu2008}.\ However, processing each channel separately would often achieve inferior performance to processing the color channels jointly \cite{mairal2008sparse}.\ Later, Lebrun el al. proposed a multiscale denoising algorithm called 'Noise Clinic' \cite{noiseclinic} for blind image denoising task. This method generalizes the NL-Bayes \cite{nlbayes} to deal with signal and frequency dependent noise.\ Therefore, the methods \cite{noiseclinic,ncwebsite,Zhu_2016_CVPR} perform real color image denoising by concatenating the patches of RGB channels into a long vector.\ However, the concatenation treats each channel equally and ignores the different noise statistics among these channels.\ The method in \cite{crosschannel2016} models the cross-channel noise in real noisy images as multivariate Gaussian and the noise is removed by the Bayesian non-local means filter \cite{kervrann2007bayesian}.\ The commercial software Neat Image \cite{neatimage} estimates the noise parameters from a flat region of the given noisy image and filters the noise accordingly.\ The methods in \cite{crosschannel2016,neatimage} ignore the non-local self-similarity of natural images \cite{bm3d,wnnm}. 


Despite the success of these methods, they have many limitations. On one hand, as suggested in \cite{Liu2008,noiseclinic}, Gaussian noise, assumed by \cite{fullyblind,rabie2005robust,Liu2008}, may be inflexible for more complex noise in real images. Hence, better approximation to the noise could bring better image denoising performance \cite{Liu2008,noiseclinic}. Based on these observations, it is still needed to design an robust and effective model for blind image denoising. Few assumption and no parameter tuning would bring extra points.


\section{Contribution}
\label{sec:intro:new}

This thesis is mainly consisted by the several work I have done during my PhD study, during which I focus on designing new and better image denoising algorithms. 

Firstly, I propose a method for denoising synthetic AWGN noise, from which we can study the performance of the nonlocal self-similarity priors of natural images. In fact, we propose to learn the external NSS priors and apply the learned model on denoising AWGN noise. The proposed method achieves state-of-the-art performance on AWGN denoising on both effectiveness and efficiency. 

Basing on the success on the synthetic noise removal, I propose to exploit the power of the NSS priors in natural images to deal with the complex realistic noise in real-world noisy images. Specifically, we propose three methods exploiting the NSS priors of natural images for real noisy image denoising, which can be introduced as follows.

In the first method, I propose to learn the NSS prior from the external natural images, and then apply the learned external prior to guide the learning of the internal NSS prior of the input real noisy image. The experiments on two commonly used datasets and a new one we constructed to implement the shortage of existing datasets, demonstrate that the proposed method can achieve better performance than existing color image denoising methods such as CBM3D \cite{cbm3d}, the state-of-the-art Gaussian noise removal methods \cite{bm3d,mlp,csr}, and the real noisy image denoising methdos \cite{} including a commercial software Neat Image \cite{neatimage}, which is embeded into the famous PhotoShop CS for image processing tasks.


In the second method, I propose to employ the low rank model describe fully the the internal NSS prior, basing on the observed fact that the similar image patches can be contanated as a matrix of low rank. Different from the previous work, I extend the WNNM model and apply it to multi-channel version to make it feasible for color image denoising. 


In the third method,  is to use the sparse coding based method with additional weighting scheme to regard the local noise in real noisy images as a Gaussian and the prior is used to deal with the real noisy image.


Finally, to make my thesis more comprehensive, I construct a large benchmark of real noisy images captured by different types of famous commercial cameras, on which I also evaluate the image denoising methods mentioned above and the proposed methods in this thesis. 


The structure of this thesis is organized as follows: in the chapter 2, we review the literatures in the image denoising area; in the chapter 3, we introduce the fully external method; in the chapter 4, we introduce the external prior guided internal method; in the chapter 5, we introduce the internal method based on low ran model; in the chapter 6, we introduce the internal method based on sparse coding model; in the chapter 7, we introduce the real noisy image dataset we construct, and finaly evaluate the proposed methods with the compared competing methods, both for synthetic AWGN or Poisson noise and real noise, including the commercial software designed especially for real noise. 


\section{Thesis Structure}
\label{sec:intro:structure}


%\textbf{Chapter \ref{sec:review}: Literature Review} \\[0.2em]

%In this chapter, we review the related work and give a detailed introduction of the literature. We will first review the most representative work on additive white Gaussian noise removal. I review the detailed work on camera imaging pipeline and realistic noise generated in the camera sensors. I will also review the work on real noisy image denoising.



\textbf{Chapter \ref{sec:external}: External Nonlocal Self-Similarity Prior Learning for Synthetic Gaussian Noise Removal} \\[0.2em]

In this chapter, I will introduce our work on external nonlocal self-similarity (NSS) prior learning for synthetic Gaussian noise removal. As far as we know, this work is the first to learn the NSS priors of natural clean images, while previous work only utilize the NSS priors of input noisy image for online denoising. The advantages of this offline learning is that it can preserve the details of natural images while being much faster then most online denoising methods.


\textbf{Chapter \ref{sec:guided}: External Prior Guided Internal Prior Learning for Real Noisy Image Denoising} \\[0.2em]

In this chapter, I will introduce our work on external prior guided internal prior learning method for real noisy image denoising. This work can maintain the advantages of both sides: from the external perspective, the method can preserve the structures of natural images better than the internal methods, while from the perspective of internal method, the proposed method can recover the details of the input noisy image better than the external methods.



\textbf{Chapter \ref{sec:internallr}: Multi-channel Weighted Nuclear Norm Minimization for Real Color Image Denoising} \\[0.2em]

In this chapter, we introduce a multi-channel weighted nuclear norm minimization (MC-WNNM) method. This method regards different channels in RGB images differently to adaptively process the real color noisy images. Besides, this work also propose a new strategy for color image denoising. Experiments demonstrate that the proposed method can achieve better performance on real color image denoising than existing state-of-the-art methods, including some commercial software.



\textbf{Chapter \ref{sec:internalsc}: A Triple Weighted Sparse Coding Scheme for Realistic Noisy Image Denoising} \\[0.2em]

In this chapter, I introduce a novel sparse coding based method for real color image denoising. In this method, I regard the noise in each of the local region in the real noisy image as a Gaussian, and propose a triplely weighted scheme to deal with the complex realistic noise in real color noisy images. Experiments show that the proposed method performs better and faster than the nuclear norm based method mentioned in previous chapter.


\textbf{Chapter \ref{sec:dataset}: A Benchmark on Real Color Noisy Image, with Comprehensive Evaluation of State-of-the-art} \\[0.2em]

To fully boost the research of real color noisy image denoising, we construct a large benchmark on real color noisy images. This dataset is collected from several representative cameras with comprehensive settings on contents, lighting, ISO, shutter, and aperture, etc. Based on this newly established dataset, we fully evaluated existing denoising methods, including the methods designed for synthetic Gaussian noise and the methods designed especially for real color noise. We believe that this new dataset will largely boost the research of the image denoising especially the realistic image denoising problems.





