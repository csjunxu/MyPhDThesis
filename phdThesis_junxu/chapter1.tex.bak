\chapter{Introduction}

%
Object tracking is one of the hottest topics in the field of computer vision. As the technology advances, the video cameras become inexpensive and the computers are equipped with high computation power. The automatic video analysis has much attention, which usually includes three steps: detecting objects of interest, tracking objects from frame to frame, and analyzing the tracked objects to recognize their behaviors~\cite{Yilmaz_CSUR_2006}. Therefore, visual tracking is a prerequisite in many practical applications such as visual surveillance, activity or behavior recognition, traffic monitoring, to name a few.


\section{Overview of A Tracking System}
 %
 A typical tracking system mainly includes three components~\cite{Babenko_pami_2011,kwon2011tracking}: an appearance model, a motion model, and a search strategy to find the most possible object location in the current frame.
 \begin{itemize}
   \item \textbf{Appearance Model:} it is composed of two components: object representation and statistical model. Object representation focuses on how to use different types of visual features to design a robust object descriptor. Then, a statistical model is learned with these descriptors for identifying the object using statistical learning techniques.
   \item \textbf{Motion Model:} it is often formulated as a dynamic state estimation problem. For example, the target location is defined by a sequence of states $X^t: t=1,2,\ldots$ that is over time determined by the dynamic equation: $X^t=f(X^{t-1},W^{t})$, where $W^t$ is noise. Then, the relationship between the measurement $Z^t$ and the state is formulated as $Z^t=h(X^t,N^t)$, where $N^t$ is the noise independent of noise $W^t$. The motion estimation is often predicted by techniques of Kalman filters~\cite{kalman1960new} or particle filters~\cite{isard1998condensation}.
   \item \textbf{Search Strategy:} a simple greedy search strategy or maximizing a posterior estimation $p(X^t|Z^{1,\ldots,t})$ is adopted.
 \end{itemize}
 %

\section{Overview of Appearance Models}
%
Because the challenging factors (e.g., pose variation, illumination change, partial or full occlusion) in visual tracking often make the object appearance change much, an adaptive appearance model plays an important role for robust object tracking. Therefore, a larger number of tracking algorithms concentrate on designing an effective appearance model that is able to deal with the above-mentioned challenges. In the following sections, we will briefly introduce some representative appearance models for visual tracking, including the object representation and statistical models.
%
\subsection{Object Representation}
The object representation methods in visual tracking can be generally categorized into two classes: the global and local object representations.

%
\noindent{\textbf{Global Object Representation:}}
The global object representation methods model the holistic characteristics of object appearance. Raw pixel values and color histograms are two popular global visual descriptors because of their simplicity and efficiency. Raw pixel representations directly use the color or intensity values to represent the target object, which is very simple and efficient for fast visual tracking. These representations mainly include two classes: the vector-based~\cite{silveira2007real,Ho_CVPR_2004,Ross_IJCV_2008,Mei_PAMI_2011,bao2012real,kwon2009tracking} and the matrix-based methods~\cite{wang2007object,li2007robust,li2008visual}. The vector-based methods learn a high-dimensional vector via Principle Component Analysis (PCA) method~\cite{Ross_IJCV_2008} or sparse representation method~\cite{Mei_PAMI_2011,zhong2012robust,jia2012visual,bao2012real} to represent the object region. However, these methods may have the small-sample-size problem~\cite{li2013survey}. To address this problem, the matrix-based methods directly adopt high-order tensors~\cite{li2007robust,li2008visual} or 2D matrices~\cite{wang2007object} to represent the target region. However, the raw pixel features are sensitive to illumination variation and noise, thereby leading to unstable tracking results. To alleviate this problem, other features (e.g., edge~\cite{wang2007adaptive} and texture~\cite{allili2007object}) can be fused into raw pixel features, resulting in favorable results.
%

%
Color histogram representation methods are popular in visual tracking because of their effectiveness and efficiency in dealing with shape deformation and partial occlusion. These methods have been used in the mean-shift tracking method~\cite{Comaniciu_PAMI_2003} and the particle filter based algorithm~\cite{perez2002color,kwon2008tracking}.
Bradski~\cite{bradski1998real} proposed to utilize a color histogram in the Hue Saturation Value color space to represent object, and then embed this histogram into an adaptive mean shift frame for efficient visual tracking. However, this color histogram does not exploit the spatial information of the target that may result in inaccurate outputs when parts of background have similar color to the target. To address this problem, the mean-shift tracking algorithm~\cite{Comaniciu_PAMI_2003} utilizes spatially weighted color histogram in the RGB color space for object representation. All the above mean-shift based methods~\cite{bradski1998real,Comaniciu_PAMI_2003} utilize a deterministic search strategy to find the region in the next frame with a color histogram that best matches the reference color histogram model. However, they may not perform well in the complex background or when the target has been occluded severely. The particle filter based method~\cite{perez2002color} can deal with these challenging situations because it utilizes sampling technique that permits tracking multiple posterior modes, thereby making it enable to escape from background distraction and recover after severe occlusion.

%
In all the tracking algorithms mentioned above, only a single holistic histogram are utilized for object representation, which does not take into account the structure appearance information, thereby making it unable to work well when the object appearance has large variations. To solve these problems, the multi-cue histogram methods are proposed, which include joint spatial-feature model and patch-division model. In~\cite{elgammal2003probabilistic}, a joint spatial feature (e.g., $(x,y,\textbf{f})$, where $(x,y)$ is the location information and $\textbf{f}$ is image feature) distribution is used for object representation that can preserve the appearance structure, thereby making the tracking robust to small local deformations and partial occlusion. Yang et al.~\cite{yang2005efficient} proposed a new similarity measure that is applied to joint spatial feature space for efficient mean-shift tracking. The patch-division strategy separates the object region into a set of patches, and then takes into account the geometric relationship between patches, encoding the spatial information into the appearance models.
%
\begin{figure*}[t]
\begin{center}
\includegraphics[width=0.6\linewidth]{images/fragetracker}
   \caption{Patch-division object representation (from~\cite{li2013survey}). Right figures illustrate the matching processing between different patches.}
\label{fig:fragetracker}
\end{center}
\end{figure*}
%
In~\cite{perez2002color}, a multi-part model is proposed to
integrate the relative spatial arrangement of different patches within the target region, which captures the coarse spatial layout of colors, leading to more accurate tracking results. In~\cite{Adam_CVPR_2006}, the integral histogram method~\cite{porikli2005integral} is used to efficiently compute the histogram in each patch of a multi-part model (See Figure~\ref{fig:fragetracker}), and the final tracking location is determined by combining each patch vote, resulting in robust results even in severe occlusion.
%

%
%
\begin{figure*}[t]
\begin{center}
\includegraphics[width=0.6\linewidth]{images/haarftr}
   \caption{Illustration of Haar-like features. Left: three different Haar-like feature templates (the signs of the weights for the blue rectangle regions are different from those for the red rectangle regions).}
\label{fig:haar}
\end{center}
\end{figure*}
%
\noindent{\textbf{Local Object Representation:}}
%
The global object representation is sensitive to the global appearance changes caused by illumination change, pose variation, and non-rigid deformation, etc. To handle these challenging factors, more visual features (e.g., location, shape, texture) have been used to learn the appearance models. On the contrary, the local object representation encodes the local structural information of object appearance, which is robust to global appearance variations, and has been attracting lots of attentions in recent years~\cite{Babenko_pami_2011,Grabner_BMVC_2006,Grabner_ECCV_2008,Hare_ICCV_2011,Kalal_CVPR_2010,Zhang_eccv_2012}. The local template based object presentation methods represent the object with an assembly of part templates.
Wu and Nevatia~\cite{wu2007detection} represented a human body as a set of body parts, and then learned part detectors via boosting a number of weak classifiers based on edgelet features. Lin et al.~\cite{lin2007hierarchical} proposed a human segmentation and detection method by hieratically matching the part-template tree to images. In~\cite{wang2011superpixel}, Wang et al. utilized superpixel segmentation to design a local template based object representation. In~\cite{Zhang_eccv_2012,Babenko_pami_2011}, the random Haar-like features are used to represent object in which each feature is computed by several local rectangle templates.
%
In~\cite{nguyen2006robust}, Garbor features are used to represent the object and local background as a set of texture patterns. Histogram of gradient (HOG) features are used for object presentation in~\cite{liu2007gradient,yu2008online}. Grabner and Bischof~\cite{Grabner_BMVC_2006} built a strong classifier via online Boosting method that selects a number of weak classifiers trained with the Haar-like features~\cite{Viola_CVPR_2001} (See Figure~\ref{fig:haar}), HOG~\cite{dalal2005histograms}, and Local Binary Patterns~\cite{ahonen2006face}.

%
\begin{figure*}[t]
\begin{center}
\includegraphics[width=1\linewidth]{images/tracking-detection}
   \caption{Basic flow of tracking by detection method.}
\label{fig:trackingdetection}
\end{center}
\end{figure*}
%
\subsection{Statistical Models}
Recently, the tracking by detection methods are very popular because of their favorable performance in dealing with many challenging factors. The tracking by detection methods pose tracking as a detection problem. As shown by Figure~\ref{fig:trackingdetection}, in each frame, the positive samples are extracted near the object location, and the negative samples are from the local context region far from the object location. Then, a classifier is updated in an online manner. Finally, the updated classifier is used to detect the object location in the next frame.

%
In general, tracking by detection algorithms can be categorized into three classes based on statistical models they used: generative, discriminative and hybrid models. Generative algorithms typically learn an appearance model and use it to search for image regions with minimal reconstruction errors as tracking results.
%
%
Black et al.~\cite{Black_IJCV_1998} learned an off-line subspace model for object representation. In~\cite{Jepson_pami_2003}, Jepson et al. proposed a Gaussian Mixture Model(GMM) with an online expectation maximization algorithm to handle appearance variations during tracking. Ho et al.~\cite{Ho_CVPR_2004} developed a tracking method using a set of learned subspace model to handle appearance variations. Instead of using pre-trained subspace, the IVT method~\cite{Ross_IJCV_2008} learns an appearance model online to adapt appearance change. Kwon et al.~\cite{Kwon_CVPR_2010} combined multiple observation and motion models in a modified particle filtering framework to deal with large scale appearance and motion variation.
%
Recently, sparse representation methods have been used in the $\ell_1$-tracker where an object is modeled by a sparse linear combination of a set of target and trivial templates~\cite{Mei_PAMI_2011} to deal with
partial occlusion, illumination change and pose variation.
%
However, the computational complexity of the $\ell_1$-tracker is rather high, thereby limiting its real-time applications. Li et al.~\cite{Li_CVPR_2011} further extended it by using the orthogonal matching pursuit algorithm for solving the optimization problem efficiently, and Bao et al.~\cite{bao2012real} improved the efficiency via accelerated proximal gradient (APG) approach. A representation based on distribution of pixels at multiple layers is proposed to describe object appearance for tracking~\cite{sevilla2012distribution}.
%
Oron et al.~\cite{oron2012locally} proposed a joint model of appearance and spatial configuration of pixels that estimates the amount of local distortion of the target object, thereby well handling rigid and nonrigid deformations. Recently, Zhang et al.~\cite{zhang2012robust} proposed a multi-task approach to jointly learn the particle representations for robust object tracking.
However, these generative models do not
take surrounding visual context into account and discard useful
information that can be exploited to better separate target object from
the background.

%
Discriminative models pose object tracking as a binary classification task in
which a classifier is learned to separate the
target object from its surrounding background within a local
region.
%
Avidan~\cite{Avidan_PAMI_2004} extended the optical flow approach with a support vector machine classifier for object tracking.
%
Collins et al.~\cite{Collins_pami_2005} demonstrated that
selecting discriminative features in an online manner improves
tracking performance.
%
In~\cite{Grabner_BMVC_2006}, Grabner et al. proposed an online boosting algorithm to select features for tracking.
%
However, these discriminative
algorithms~\cite{Avidan_PAMI_2004,Collins_pami_2005, Grabner_BMVC_2006}
utilize only one positive sample (i.e., the tracking result in the current
frame) and multiple negative samples when updating the classifier.
%
If the object location detected by the current classifier is not precise,
the positive sample will be noisy and result in a suboptimal
classifier update.
%
Consequently, errors will be accumulated and cause
tracking drift or failure~\cite{Babenko_pami_2011}.
%
In~\cite{Hare_ICCV_2011}, Hare et al. used an online structured output support vector machine (SVM) for robust tracking that can mitigate the effect of wrong labeling samples. Henriques et al.~\cite{henriques2012circulant} introduce a fast tracking algorithm that exploits the circulant structure of the kernel matrix in the SVM classifier that can be efficiently computed by the  fast Fourier transform algorithm.
%

\section{Challenges in Visual Tracking}

Although numerous visual tracking algorithms have been proposed with demonstrated success, there still exist some challenges which are summarized as follows

\begin{itemize}
  \item \textbf{Robust and Efficient Object Representation.} The object appearance often changes much by the challenging factors such as illumination changes, partial or full occlusion, non-rigid deformation, and similar background distracter, which make robust tracking very challenging. To deal with these challenging factors, complicated models are proposed, but they are less efficient to design. Usually, there is a trade-off between the efficiency and effectiveness of an object representation.
  \item \textbf{Inconsistent Objectives between Tracking and Classification.} The objective of tracking is to estimate the object location but the objective of classification in tracking by detection methods (See Figure~\ref{fig:trackingdetection}) is to predict the instance labels. Therefore, these two objectives are inconsistent during learning, leading to inaccurate estimation of object location by maximizing the classifier response~\cite{Hare_ICCV_2011}.
\end{itemize}
%
\section{Contributions of the Thesis}
%
Because the appearance model plays a key role for the success of a tracking system, in this thesis, we focus on designing robust and efficient appearance models by using effective feature selection and extraction methods. Moreover, different from most tracking by detection methods that treat tracking as a binary classification problem that is inconsistent with the objective of tracking task, our proposed algorithms explicitly couple the objective of tracking and classification via estimating a confidence map function that returns the real value of a classifier. Our contributions are summarized as follows:
 \begin{itemize}
   \item \textit{Two effective feature selection techniques are proposed to build robust appearance models.}
    Similar to object detection, the tracking by detection methods also have the sample ambiguity problem~\cite{viola2006multiple}. Recently, the multiple instance learning (MIL) based tracker has been proposed to solve the sample ambiguity problem with promising results. It puts samples into the positive and negative bags, and then selects some features with an online boosting method via maximizing the bag likelihood function to design a robust appearance model. Finally, the selected features are combined for classification. However, in MIL tracker the features are selected by a likelihood function, which can be less informative to tell the target from complex background. Moreover, important prior information about the instance labels and the most important positive sample is not exploited, thereby making the selected features less effective. In order to solve the above problems, we propose two feature selection methods:
   \begin{enumerate}
     \item
     Motivated by the active learning method, we propose an active feature selection approach which is able to select more informative features than  the MIL tracker by using the Fisher information criterion to measure the uncertainty of classification model. More specifically, we propose an online boosting feature selection approach via optimizing the Fisher information criterion, which can yield more robust and efficient real-time object tracking performance.
     \item
     We show that integrating prior information (e.g., instance labels and most important positive sample) into a supervised learning algorithm can handle visual drift more effectively and efficiently than the existing MIL tracker. We present an online discriminative feature selection algorithm which optimizes the objective function in the steepest ascent direction with respect to the positive samples while in the steepest descent direction with respect to the negative ones. Therefore, the trained classifier directly couples its score with the importance of samples, leading to a more robust and efficient tracker.

   \end{enumerate}
   \item
    \textit{An efficient feature extraction technique based on compressive sensing theory is proposed to build an efficient and effective appearance model.} The appearance model is based on features extracted from a multiscale image feature space with data-independent basis, which employs non-adaptive random projections that preserve the structure of the image feature space of objects. A very sparse measurement matrix is constructed to efficiently extract the features for the appearance model. The tracking task is formulated as a binary classification via a naive Bayes classifier with online update in the compressed domain. A coarse-to-fine search strategy is adopted to further reduce the computational complexity in the detection procedure.
   \item
   \textit{A fast and robust appearance model that exploits the spatio-temporal context information is proposed.} Our approach models the spatio-temporal correlation between the low-level features (i.e., image intensity and position) from the target and its surrounding regions in the Bayesian framework, and obtains the best target location by maximizing an object location likelihood function. Then, the Fast Fourier Transform is adopted for extremely fast learning and detection.
 \end{itemize}
 %
 %
\begin{figure}[!ht]
\begin{center}
\includegraphics[width=1\linewidth]{images/structure}
\vspace{-2mm}
\end{center}
   \caption{Structure of the following chapters. The AFS and ODFS methods explore the feature selection techniques while the CT method exploits the simple random feature extract without learning. All these three methods use the local Haar-like features while the STC method uses the global image intensity features with context learning.}
\label{fig:structure}
\end{figure}
\section{Outline of The Thesis}

Figure~\ref{fig:structure} outlines the structure of the following chapters that are based on papers~\cite{kaihua2013afs,kaihua2013odfs,kaihua2013fct,kaihua2012stc}. In Chapter~\ref{chap:AFS}, we propose an active feature selection (AFS) method that improves the MIL feature selection method~\cite{Babenko_pami_2011}. However, it may be unnecessary for feature selection in the MIL framework because the instance labels are assumed to be known even in the MIL framework. In Chapter~\ref{chap:odfs}, we further propose an online discriminative feature selection (ODFS) method that directly selects features on the instance level by a supervised learning method. The feature selection techniques in Chapter~\ref{chap:AFS} and Chapter~\ref{chap:odfs} select a subset of dimensions that contain more discriminative information while removing redundancy and noise. Contrary to the feature selection methods, in Chapter~\ref{chap:CT}, we exploit the information from all dimensions rather than a subset of them, and experiments demonstrate our method yields favorable results in terms of both efficiency and robustness. Different from the sophisticated feature selection and extraction methods used in chapters~\ref{chap:AFS}, \ref{chap:odfs}, and ~\ref{chap:CT}, in Chapter~\ref{chap:STC} we show that the low-level features (e.g., the image intensity) that integrate the spatio-temporal context information can build a fast and robust appearance model. Finally, we present our conclusions and future work in Chapter~\ref{chap:conclusion}.  