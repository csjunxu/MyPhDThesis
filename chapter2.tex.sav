\chapter{Robust Object Tracking via Active Feature Selection}
%
\section{Introduction}
\label{sec:introduction}
The tracking by detection methods treat tracking as a classification task, which separates object from its local background via a discriminative classifier. When training the classifier, the selection of positive and negative samples affects much the performance of the tracker. Most trackers~\cite{avidan2004support,avidan2007ensemble,Grabner_BMVC_2006,liu2007gradient,wang2005online} only choose one positive sample, i.e., the tracking result in the current frame. If the tracked target location is not accurate, the classifier will be updated based on a less effective positive sample, thereby leading to visual drift over time. To alleviate the drifting problem, multiple samples near the tracked target location can be used to train the classifier. However, the ambiguity occurs if the traditional supervised learning method is used to train the classifier~\cite{Babenko_pami_2011}.

%
Recently, a multiple instance learning (MIL) approach~\cite{Babenko_pami_2011} is proposed to solve the ambiguity problem in tracking. The samples are put into bags and only the labels of the bags are provided. The bag is positive if one or more instances in it are positive while the bag is negative when all of the instances in it are negative. The samples near the tracking location are put into the positive bag while the samples far from the tracking location are put into the negative bag. Then, a classifier is designed by optimizing the bag likelihood function. To handle the appearance variations over time, an online MIL boosting algorithm is proposed to greedily select the discriminative features from a feature pool by maximizing the bag likelihood function. Finally, the selected weak classifiers (each corresponds to a feature) are linearly combined to a strong classifier. The strong classifier is then used to separate object from background in the next frame. Empirical studies on some challenging sequences have shown that the MIL tracker can better handle visual drift than most state-of-the-art trackers.
%

Despite its success, the MIL tracker~\cite{Babenko_pami_2011} has the following shortcomings. First, the selected features may be less informative. In order to make the classifier discriminative enough, a relatively large number of features are selected from the feature pool. This enlarges the computational burden. Second, the more features are selected, the higher the probability that less discriminative features are included. These less discriminative features can degrade the performance of the classifier, and cause drift over time.

%
To address the above problems, inspired by the active learning method~\cite{settles2010active} we propose a novel feature selection scheme to select the more informative features for visual tracking, namely, the active feature selection (AFS) based tracker. An online feature selection scheme is proposed by optimizing a bag Fisher information function instead of the bag likelihood function. Thus, the selected features are much more informative than those selected by the bag likelihood function in MIL tracker~\cite{Babenko_pami_2011}. Consequently, we can use less features to design a classifier which is more efficient and robust than the classifier induced by the MIL tracker. Our experimental evaluations on challenging video clips validate the superior performance of AFS tracker to state-of-the-art trackers in terms of efficiency, accuracy and robustness.
%
\begin{figure}[t]
\begin{center}
\includegraphics[width=0.8\linewidth]{images/systemAFS}
\vspace{-2mm}
\end{center}
\caption{Illustration of how our AFS tracking system works}
\label{fig:systemAFS}
\end{figure}
%
\section{Tracking with Adaptive Feature Selection}
%
\subsection{System Overview}
Figure~\ref{fig:systemAFS} illustrates the basic flow of our tracking system. There are two important components in our tracking system. One is how to detect the object location in the new frame, and the other is how to update the classifier. We represent the object location in the $t$-th frame as $\textbf{l}_t^\star$. A set of patches near the old object location are cropped as $D^s=\{\textbf{x}||\textbf{l}(\textbf{x})-\textbf{l}_{t-1}^\star|<s\}$, where $s$ is a search radius and $\textbf{x}$ denotes the image patch. Then, we compute the classifier response $H(\textbf{x})$ for all $\textbf{x}\in D^s$ in which the classifier $H(\textbf{x})=\sum_k h_k(\textbf{x})$ is a linear combination of some weak classifier $h_k(\textbf{x})$. Finally, we update the object location using a greedy strategy
%
\begin{equation}
\textbf{l}_t^\star=\textbf{l}\big({\arg\max}_{\textbf{x}\in D^s}H(\textbf{x})\big).
\label{eq:argmaxHx}
\end{equation}
%
After the object location is updated, a set of samples $D^r=\{\textbf{x}||\textbf{l}(\textbf{x})-\textbf{l}_t^\star|<r\}$, where $r$ is a scalar radius, are cropped and put into a positive bag. For the negative samples, we take a small random set of samples from set $D^{r,\beta}=\{\textbf{x}|r<|\textbf{l}(\textbf{x})-\textbf{l}_t^\star|<\beta\}$ , where $\beta$ is a scalar radius, because $D^{r,\beta}$ contains a large number of samples. Note that injecting the negative samples far from the object location may be beneficial for classification if the backgrounds between two consecutive frames do not changes much. On the contrary, injecting the negative samples far from the object location may degrade the tracking performance because the negative patches between two consecutive frame will correlate each other less, and more noises from the background are added into the training procedure. We put all the negative samples into a negative bag. Then, we update the classifier via maximizing the bag Fisher information loss function in an online manner.

%
\subsection{MIL Tracker}
%
We first briefly review the MIL tracker~\cite{Babenko_pami_2011} that is most related to our work. The MIL method was introduced by Dietterich et al.~\cite{dietterich1997solving} to deal with the drug activity prediction. Suppose that we have a set of $N$ bags $\{X_1,\ldots,X_N\}$, where each bag $X_i=\{\textbf{x}_{i1},\ldots,\textbf{x}_{in_i}\}$  has $n_i$ instances. Let $y_i\in\{0,1\}$ be the label of bag $X_i$ and $y_{ij}\in\{0,1\}$ the label of instance $\textbf{x}_{ij}$. The MIL defines that if bag $X_i$ is positive, then at least one of the instance labels in it is positive. If the bag label is zero, then all of the corresponding instance labels are zero. The MIL tracker seeks for the discriminative classifier $H(\textbf{x})$, which can return the conditional probability $p(y=1|\textbf{x})$. Since the discriminative classifier is an instance classifier that is related to the conditional probabilities of the instances, the Noisy-OR model is used to exploit the conditional probabilities of the instances to estimate the bag probability
%
\begin{equation}
p(y_i=1|X_i)=1-\prod_j(1-p(y_{ij}=1|\textbf{x}_{ij})),
\label{eq:noisyOR}
\end{equation}
%
where the instance probability $p(y_{ij}=1|\textbf{x}_{ij})$ is modeled as
%
\begin{equation}
p(y_{ij}=1|\textbf{x}_{ij})=\sigma(H(\textbf{x}_{ij})),
\label{eq:instanceprob}
\end{equation}
%
where $\sigma(z)=\frac{1}{1+e^{-z}}$  is the sigmoid function, and the classifier $H(\textbf{x})$ is learned by maximizing the following bag log likelihood loss function
%
\begin{equation}
\mathcal{L}(H)=\sum_i\bigg(y_i\log(p(y_i=1|X_i))+(1-y_i)\log(1-p(y_i=1|X_i))\bigg).
\label{eq:loglikehood}
\end{equation}
%

%
To handle the appearance changes over time, an online MIL boosting approach is proposed to update the classifier $H(\textbf{x})$. First, a weak classifier pool is maintained, and then a small number of weak classifiers are greedily selected from the pool by maximizing the log likelihood of the bag
%
\begin{equation}
h_k={\arg\max}_{h\in\Phi}\mathcal{L}(H_{k-1}+h),
\label{eq:argmaxLoglike}
\end{equation}
%
where $H_{k-1}=\sum_{m=1}^{k-1}h_m$ is a strong classifier by assembling the first $k-1$ weak classifiers, and $\Phi=\{h_1,\ldots,h_M\}$ is the weak classifier pool with $M$ weak classifiers. Similar to the boosting feature selection method in face detection~\cite{viola2001rapid}, weak classifier selection can be viewed as feature selection because each weak classifier corresponds to a feature. Feature selection has been proven very useful to reduce visual drift in visual tracking~\cite{Collins_pami_2005}. Moreover, the classifier can run efficiently because the number of the selected features is much smaller than the size of the feature pool.
%
\subsection{Principle of AFS}
From the formulation of the log likelihood function in~(\ref{eq:loglikehood}), we can see that the feature selection scheme in~(\ref{eq:argmaxLoglike}) is to select the weak classifiers that maximize the conditional probability $p(y_i=1|X_i)$ of the positive bag $X_i$ while minimizing the conditional probability $p(y_j=1|X_j)$ of the negative bag $X_j$. We argue that the selected features can be less informative than those selected by optimizing the Fisher information function in our method to be introduced below. Therefore, to ensure the enough discriminative information, in the MIL tracker a relatively large number of features ($K=50$) are selected from a feature pool with a relatively large size ($M=250$), while in our AFS tracker only $K=15$ features are selected from a pool with $M=50$ features. Moreover, if too many features are selected, the discrimination between the object and background features can be reduced.

%
Similar to the MIL tracker~\cite{Babenko_pami_2011}, we take the classifier as the following form
%
\begin{equation}
H(\textbf{x})=\mathbf{\alpha}^\top \textbf{h}(\textbf{x}),
\label{eq:strongclf}
\end{equation}
%
where $\mathbf{\alpha}=(\alpha_1,\ldots,\alpha_M)^\top$ is a weight vector and $\textbf{h}=(h_1,\ldots,h_M)^\top$ is a weak classifier vector. Each element in $\textbf{h}$ is a decision stump function that returns the binary labels (i.e., $+1$ or $-1$). In order to devise the classifier $H(\textbf{x})$, we need to estimate its corresponding parameters $\mathbf{\alpha}$. The  Cramer-Rao inequality~\cite{cover2012elements} shows that any unbiased estimator $\textbf{t}_n$ of $\mathbf{\alpha}$ based on $n$ independent and identically distributed samples from the probability $p(y|\mathbf{\alpha})$, the covariance of $\textbf{t}_n$ should satisfy that $cov(\textbf{t}_n)-\frac{1}{n}I(\mathbf{\alpha})^{-1}$ is a nonnegative definite matrix, where $I(\mathbf{\alpha})$ is the Fisher information matrix defined as~\cite{cover2012elements}
%
\begin{equation}
I(\mathbf{\alpha})=-\int p(y|\mathbf{\alpha})\frac{\partial^2}{\partial\mathbf{\alpha}^2}\log p(y|\mathbf{\alpha})dy.
\label{eq:fisherinformation}
\end{equation}
%
The Fisher information matrix represents the overall uncertainty of the classification model which is often used in active learning method~\cite{zhang2000value}. In~\cite{zhang2000value}, for each query in active learning, an unlabeled sample that can decrease the Fisher information most is selected. To measure the uncertainty of the classification model in our AFS tracker, we use the Fisher information matrix based on the samples from the bag probability
%
\begin{equation}
I(\mathbf{\alpha})=\sum_i\bigg(y_i p(y_i|X_i,\mathbf{\alpha})\frac{\partial^2}{\partial\mathbf{\alpha}^2}\log p(y_i|X_i,\mathbf{\alpha})+(1-y_i)p(y_i|X_i,\mathbf{\alpha})\frac{\partial^2}{\partial\mathbf{\alpha}^2}\log p(y_i|X_i,\mathbf{\alpha})\bigg)+\delta I_m,
\label{eq:fisherinformationsum}
\end{equation}
%
where $y_i\in\{0,1\}$ is the bag label and $\delta I_m$ (where $\delta>0$ is a scalar parameter and $I_m$ is an identity matrix) is added to make $I(\mathbf{\alpha})$ non-singular. Note that $\delta I_m$ is a trivial term that can be eliminated in our feature selection criterion~(\ref{eq:argmaxHx}). In~(\ref{eq:fisherinformationsum}), $p(y_i=1|X_i,\mathbf{\alpha})$ and $p(y_i=0|X_i,\mathbf{\alpha})$ are expressed as follows by combining~(\ref{eq:noisyOR}),~(\ref{eq:instanceprob}) and~(\ref{eq:strongclf})
%
\begin{equation}
p(y_i=1|X_i,\mathbf{\alpha})=1-\prod_j(1-\sigma(\mathbf{\alpha}^\top\textbf{h}(\textbf{x}_{ij}))),
p(y_i=0|X_i,\mathbf{\alpha})=\prod_j(1-\sigma(\mathbf{\alpha}^\top\textbf{h}(\textbf{x}_{ij}))).
\label{eq:noisyORprob}
\end{equation}
%
Note that our information matrix~(\ref{eq:fisherinformationsum}) is different from the object functions of the recently developed multiple-instance active learning (MIAL) methods~\cite{settles2008multiple,zhang2010interactive} because our objective is to measure the uncertainty of the classification model for the selected features when the bag labels are known, while the objective of MIAL is to measure the uncertainty of the classification model for an unlabeled sample.

%
The inverse Fisher information matrix $I(\mathbf{\alpha})^{-1}$ is the lower bound of the covariance matrix of the estimated $\mathbf{\alpha}$~\cite{cover2012elements}. As a particular case, $det(I(\mathbf{\alpha}))^{-1}$ is the lower bound of the product of the variances for the elements in $\mathbf{\alpha}$. Thus, Liao et al.~\cite{liao2005logistic} proposed to select the samples that maximize $det(I(\mathbf{\alpha}))$ for active learning to reduce the uncertainty of $\mathbf{\alpha}$. However, since it is difficult to compute $det(I(\mathbf{\alpha}))$ in our objective function~(\ref{eq:fisherinformationsum}), we relax it to minimize the trace of matrix $I(\mathbf{\alpha})$ (denote by $tr(I(\mathbf{\alpha}))$) because the upper bound of $det(I(\mathbf{\alpha}))$ is $\big(\frac{1}{m}tr(I(\mathbf{\alpha}))\big)^m$. It is easy to validate that $det(I(\mathbf{\alpha}))\leq\big(\frac{1}{m}tr(I(\mathbf{\alpha}))\big)^m$ as follows: since $I(\mathbf{\alpha})$ is a positive definite symmetric matrix~\cite{cover2012elements}, all of its eigenvalues $\{\lambda_i>0,i=1,\ldots,m\}$ are positive~\cite{horn1990matrix}. Thus, we have the following inequality~\cite{horn1990matrix}
%
\begin{equation}
det(I(\mathbf{\alpha}))=\prod_{i=1}^m\lambda_i\leq\bigg(\frac{1}{m}\sum_{i=1}^m\lambda_i\bigg)^m=\bigg(\frac{1}{m}tr(I(\mathbf{\alpha}))\bigg)^m,
\label{eq:detI}
\end{equation}
%
where $tr(I(\mathbf{\alpha}))$ is represented by
%
\begin{equation}
\begin{aligned}
tr(I(\mathbf{\alpha}))=-m\sum_i\bigg(y_i\bigg(\sum_j p_i p_{ij}(1-p_{ij})+ p_{ij}(\frac{p_{ij}}{p_i}-1)\bigg)
+(1-y_i)p_i\sum_j p_{ij}(1-p_{ij})\bigg)+m\delta,
\label{eq:trIsum}
\end{aligned}
\end{equation}
%
where $p_i=p(y_i|X_i,\mathbf{\alpha})$ and $p_{ij}=p(y_{ij}|\textbf{x}_{ij},\mathbf{\alpha})$. In~(\ref{eq:trIsum}), we have set $\textbf{h}(\textbf{x})^\top\textbf{h}(\textbf{x})=m$ because each element $h_i\in\{+1,-1\}$ in $\textbf{h}(\textbf{x})$ is a decision stump function.

%
Although the above equation (\ref{eq:trIsum}) seems complex, its physical meaning is simile. For the positive bag, as learning proceeds and the bag probability approaches to the target, we have $p(y_i=1|X_i,\mathbf{\alpha})\approx 1$~\cite{viola2006multiple}. Thus the component of the positive bag in $tr(I(\mathbf{\alpha}))$ can be simplified to $-m(p(y_i=1|X_i,\mathbf{\alpha})-1)\sum_j p(y_{ij}=1|\textbf{x}_{ij},\mathbf{\alpha})(1-p(y_{ij}=1|\textbf{x}_{ij},\mathbf{\alpha}))$.
In order to minimize this function, we need to maximize two terms $p(y_i=1|X_i,\mathbf{\alpha})$ and $p(y_{ij}=1|\textbf{x}_{ij},\mathbf{\alpha})(1-p(y_{ij}=1|\textbf{x}_{ij},\mathbf{\alpha}))$. Similar to the bag log likelihood function~(\ref{eq:loglikehood}), the first term is to maximize the conditional probability of the positive bag. The second term reaches its maximum value at $p(y_{ij}=1|\textbf{x}_{ij},\mathbf{\alpha})=0.5$, which measures the most classification uncertainty for instance $\textbf{x}_{ij}$. The component of the negative bag in $tr(I(\mathbf{\alpha}))$ also contains two parts: $p(y_i=0|X_i,\mathbf{\alpha})$ and $p(y_{ij}=0|\textbf{x}_{ij},\mathbf{\alpha})(1-p(y_{ij}=0|\textbf{x}_{ij},\mathbf{\alpha}))$. The analysis for these two components is the same as those for the positive bag. Therefore, minimizing $tr(I(\mathbf{\alpha}))$ can be deemed as a tradeoff between the bag probability and the classification uncertainty for the instances. In the following, we propose an online AFS approach to selecting the informative features via minimizing $tr(I(\mathbf{\alpha}))$.

%
\subsection{Online AFS Boosting}
We take a statistical view of boosting~\cite{friedman2000additive} where the weak classifiers (each weak classifier corresponds to a feature) are selected sequentially to optimize a specific objective function $\mathcal{F}$  as
%
\begin{equation}
(h_k,\alpha_k)={\arg\min}_{h\in\Phi,\alpha\in\mathbb{R}}\mathcal{F}(H_{k-1},\alpha h),
\label{eq:onlinemin}
\end{equation}
%
where $H_{k-1}=\sum_{i=1}^{k-1}h_i$ is a strong classifier with the first $k-1$ weak classifiers and $\Phi$ is the set of all possible weak classifiers. For online learning, we always maintain a pool of $M$ candidate weak classifiers. When updating the strong classifier, we first incrementally update the weak classifiers in the pool with the newly cropped samples, and then select sequentially $K<M$ the most discriminative weak classifiers from the pool by minimizing the Fisher information criterion
%
\begin{equation}
(h_k,\alpha_k)={\arg\min}_{h\in\{h_1,\ldots,h_M\},\alpha\in\mathbb{R}}F(H_{k-1},\alpha h),
\label{eq:onlinemin2}
\end{equation}
%
where $F(H_{k-1}+\alpha h)=F(\mathbf{\alpha}^\top\textbf{h})=tr(I(\mathbf{\alpha}))$ with $\mathbf{\alpha}=(\alpha_1,\ldots,\alpha_{k-1},\alpha)^\top$ and $\textbf{h}=(h_1,\ldots,h_{k-1},h)^\top$. To simply the problem, as in the MIL tracker~\cite{Babenko_pami_2011}, in our implementation we integrate the scalar weights $\mathbf{\alpha}$  into the weak classifiers $\textbf{h}$  in order to return real values. Therefore, the weight vector $\mathbf{\alpha}$  cannot be used to indicate the importance of the weak classifiers. Note that our feature selection criterion~(\ref{eq:onlinemin2}) is a greedy forward feature selection method. Though this greedy feature selection method is sub-optimal, it is very efficient for visual tracking.
%
Algorithm~\ref{alg:onlineAFSBoosting} shows the pseudo-code of online AFS Boosting, which is the key part of the tracking algorithm illustrated in Figure~\ref{fig:systemAFS}.
%
\begin{algorithm}
\caption{Online AFS Boosting}
\begin{algorithmic}\label{alg:onlineAFSBoosting}
\STATE \textbf{Input:} Dataset
$\{X_i,y_i\}_{i=0}^N$, where $X_i=\{\textbf{x}_{i1},\textbf{x}_{i2},\ldots\}$ is the $i$-th bag and $y_i\in\{0,1\}$
\begin{enumerate}\setlength{\itemsep}{-\itemsep}
\item Update all the $M$ weak classifiers in the pool with data $\{\textbf{x}_{ij},y_i\}$
\item Initialize $H_0(\textbf{x}_{ij})=0$ for all $i,j$
\item \textbf{For} $k=1$ to  $K$ \textbf{do}
\item \quad \textbf{For} $m=1$ to $M$ \textbf{do}
\item \quad\quad $\mathcal{F}_m=\mathcal{F}(H_{k-1}+h_m)$
\item \quad \textbf{End for}
\item \quad $m^{\star}={\arg\min}_{m}(\mathcal{F}_{m})$
\item \quad $h_{k}\leftarrow h_{m^{\star}}$
\item \quad $H_{k}\leftarrow H_{k-1}+h_k$
\item \textbf{End for}
\end{enumerate}
\STATE\textbf{Output:} Classifier
$H(\textbf{x})=\sum_{k=1}^{K}h_{k}(\textbf{x})$
\end{algorithmic}
\end{algorithm}
%
\subsection{Advantages over The MIL Tracker}
Our Fisher information criterion~(\ref{eq:onlinemin2}) can select the features which are much more informative than those selected from the log likelihood criterion~(\ref{eq:argmaxLoglike}) in the MIL tracker, because our criterion maximizes the uncertainty of the selected features. Thus, we only need to actively select a small number of weak classifiers which are more discriminative than those used in the MIL tracker. In our experiments, we select $K=15$ weak classifiers from a pool with $M=50$ candidate weak classifiers, which are much less than the MIL tracker where $K=50$ and $M=250$. Although our objective function~(\ref{eq:trIsum}) seems more complex than that used in MIL tracker (i.e.,~(\ref{eq:loglikehood})), their computational complexities are comparative because only addition and multiplication are needed to compute bag and instance probabilities. Moreover, the MIL tracker needs to update more classifiers ($M=250$) than ours ($M=50$), and select more weak classifier ($K=50$) than our method ($K=15$). Thus, overall our tracker is more efficient than MIL tracker (please refer to our experimental results in next section). In addition, because our selected weak classifiers are more informative than those selected by the MIL tracker, our appearance model (i.e., the strong classifier) is able to better handle visual drift.
%
\subsection{Implementation Details}
We use the same Haar-like image features as those used by the MIL tracker~\cite{Avidan_pami_2004} which can be efficiently computed using the integral image technique~\cite{Viola_CVPR_2001}. Each feature $f_i$ is a Haar-like image feature computed by the sum of weighted pixels in $2\sim4$ randomly selected rectangles. Each weak classifier $h_i$ returns the log odds ratio
%
\begin{equation}
h_i=\log\bigg(\frac{p(y=1|f_i(\textbf{x}))}{p(y=0|f_i(\textbf{x}))}\bigg)=\log\bigg(\frac{p(f_i(\textbf{x})|y=1)}{p(f_i(\textbf{x})|y=0)}\bigg),
\label{eq:weakclf}
\end{equation}
%
where we assume uniform prior $p(y=1)=p(y=0)$, $p(f_i(\textbf{x})|y=1)\sim \mathcal{N}(\mu_1,\sigma_1)$ and $p(f_i(\textbf{x})|y=0)\sim \mathcal{N}(\mu_0,\sigma_0)$. The parameters $\mu_t,\sigma_t,t\in\{0,1\}$ can be incrementally updated based on maximal likelihood estimation~\cite{bishop2006pattern}
%
\begin{equation}
\mu_t\leftarrow\gamma\mu_t+(1-\gamma)\mu,
\sigma_t\leftarrow\sqrt{\gamma\sigma_t^2+(1-\gamma)\sigma^2+\gamma(1-\gamma)(\mu_t-\mu)^2},
\label{eq:onlineupdate}
\end{equation}
%
where $\{(\textbf{x}_1,y_1),\ldots,(\textbf{x}_n,y_n)\}$ are the new data, $0<\gamma<1$ is a learning parameter, $\mu=\frac{1}{n}\sum_{k|y_i=t}f_i(\textbf{x}_k)$ and $\sigma=\sqrt{\frac{1}{n}\sum_{k|y_i=t}(f_i(\textbf{x}_k)-\mu)^2}$.
%
\section{Experimental Results}
%
As the proposed AFS tracker is developed to address several issues of MIL based tracking method (See Section~\ref{sec:introduction}), we compare it with the MIL tracker~\cite{Babenko_pami_2011} on $12$ challenging video sequences (all are publicly available). The other compared trackers are: fragment tracker (Frag)~\cite{Adam_CVPR_2006}, online AdaBoost tracker (OAB)~\cite{Grabner_BMVC_2006}, semi-supervised boosting tracker (SemiB)~\cite{Grabner_ECCV_2008}, incremental visual tracker (IVT)~\cite{Ross_IJCV_2008}, $\ell_1$-tracker~\cite{Mei_PAMI_2011}, and visual tracking decomposition (VTD) method~\cite{Kwon_CVPR_2010}. The default setting for the MIL tracker is to select $K=50$ weak classifiers from a pool with $M=250$ candidate weak classifiers. We also test the MIL tracker with setting $K=15$ and $M=50$ (we call it $MIL_{15}$).

%
\textit{We fix the parameters of the proposed tracker for all the experiments to demonstrate its robustness and stability}. For the other competing algorithms, we use the original source codes or binary codes provided by the original authors~\cite{Adam_CVPR_2006,Grabner_BMVC_2006,Grabner_ECCV_2008,Ross_IJCV_2008,Kwon_CVPR_2010,Mei_PAMI_2011} and tune their parameters for best performance. Since all the competing trackers (except for~\cite{Adam_CVPR_2006}) involve randomness, we repeat each experiment $10$ times and report the average results. Our tracker is implemented in MATLAB and runs at $15$ frames per second on a Pentium Dual-Core $2.10$ GHz CPU with $1.95$ GB RAM. The videos used in the experiments can be found at \url{ http://youtu.be/3UobcBa-V1Q}. TABLE I lists the speed of all trackers in terms of average frames per second (FPS). Note that the source code of the MIL tracker is written in C++ which runs at $10$ FPS, while the $MIL_{15}$ tracker runs at 25 FPS. However, as shown in Section 4.2, the MIL15 tracker performs poorly in most experiments. We also implemented our algorithm in C++ ad it runs at 35 FPS without optimization, which is more than 3 times faster than the MIL tracker.
%
\begin{table*}[t]
\caption{Average frames per second (FPS) of AFS and other state-of-the-art trackers}
{
\center\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|}\hline
Traker   &Frag &OAB  &MIL  &$MIL_{15}$ &SemiB   &IVT   &$\ell_1$   &VTD   &AFS\\\hline
Average FPS &3    &8    &10         &25      &6     &11          &0.1  &0.01  &15\\\hline

\end{tabular}

}
\end{table*}
%
\subsection{Experimental Setup}
%
We set the radius $r=4$ for cropping the samples in the positive bag which generates $45$ samples. The output radius for the set $D^{r,\beta}$ that generates negative samples is set to $\beta=35$. Then, we randomly select $45$ negative samples from $D^{r,\beta}$ to construct the negative bag. The radius for searching the new object location in the next frame is set to $s=25$ which is large enough to handle fast motion (we have tested different parameter $s$ and found the results are stable when we set $20<s<30$) and about $2000$ samples are drawn, which is the same as that in the MIL tracker. Therefore, this procedure is time-consuming if too many weak classifiers are used to design the strong classifier. Our tracker uses $K=15$ weak classifiers and thus is much more efficient than the MIL tracker which sets $K=50$. Moreover, in AFS the number of candidate weak classifiers in the pool is set to $M=50$, which is also less than that of the MIL tracker ($M=250$). The learning parameter is set to $\gamma=0.85$.  
%
\subsection{Qualitative Evaluation}